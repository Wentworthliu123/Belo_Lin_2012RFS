{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48d9793d-06da-4810-a6cc-58d8ced22b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# running.ipynb (PYTHON)\n",
    "#     Replication of Belo Lin 2012 RFS.\n",
    "#     by Xinyu 2022.02.03\n",
    "##################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wrds\n",
    "import datetime as dt\n",
    "from dateutil.relativedelta import *\n",
    "from pandas.tseries.offsets import *\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import importlib\n",
    "import computation\n",
    "import output\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f3816ce-0944-4b74-acab-0b11dfc84df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# Compustat Block #\n",
    "###################\n",
    "# note that in the comp.funda and similar tables, there is no sic but just sich, if one wants to access sic directly like from the web query, one can check the comp.names table\n",
    "conn=wrds.Connection()\n",
    "comp = conn.raw_sql(\"\"\"\n",
    "                    select gvkey, datadate, at, pstkl, txditc,\n",
    "                    pstkrv, seq, pstk, capx, xrd, dltis, csho, cdvc, sale, ppent, invt, sppe, emp, ebit, sich as sic, cik\n",
    "                    from comp.funda\n",
    "                    where indfmt='INDL' \n",
    "                    and datafmt='STD'\n",
    "                    and popsrc='D'\n",
    "                    and consol='C'\n",
    "                    and datadate between '07/01/1965' and '12/31/2019'\n",
    "\n",
    "                    and at >= '0'\n",
    "                    and sale>='1'\n",
    "\n",
    "                    \"\"\", date_cols=['datadate'])\n",
    "# These lines below will cause lose of data records due to missing sich\n",
    "\n",
    "#                     and not sich between '6000' and '6999'\n",
    "#                     and not sich between '4900' and '4999'\n",
    "#                    and cik is not null\n",
    "comp['year']=comp['datadate'].dt.year\n",
    "\n",
    "# create preferrerd stock\n",
    "comp['ps']=np.where(comp['pstkrv'].isnull(), comp['pstkl'], comp['pstkrv'])\n",
    "comp['ps']=np.where(comp['ps'].isnull(),comp['pstk'], comp['ps'])\n",
    "comp['ps']=np.where(comp['ps'].isnull(),0,comp['ps'])\n",
    "comp['txditc']=comp['txditc'].fillna(0)\n",
    "\n",
    "# create book equity\n",
    "comp['be']=comp['seq']+comp['txditc']-comp['ps']\n",
    "comp['be']=np.where(comp['be']>0, comp['be'], np.nan)\n",
    "\n",
    "# number of years in Compustat, important to form a qualified sample\n",
    "comp=comp.sort_values(by=['gvkey','datadate'])\n",
    "comp['count']=comp.groupby(['gvkey']).cumcount()\n",
    "\n",
    "# drop rows with no be or sic\n",
    "comp = comp.dropna(subset=['be','at'])\n",
    "\n",
    "# fill nan with zeros for mostly 'sic','cik' \n",
    "# although there are nan for r&d and cdvc, atm hold out for this operation\n",
    "comp[['sic','cik']] = comp[['sic','cik']].fillna(0)\n",
    "comp[['sic','cik']] = comp[['sic','cik']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "013a04d8-3bb2-43fc-8a4f-59df007e2f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price and shares outstanding information is extracted from CRSP for calculating market value of equity.\n",
    "###################\n",
    "# CRSP Block      #\n",
    "###################\n",
    "# sql similar to crspmerge macro\n",
    "crsp_m = conn.raw_sql(\"\"\"\n",
    "                      select a.permno, a.permco, a.date, b.shrcd, b.exchcd,b.siccd,\n",
    "                      a.ret, a.retx, a.shrout, a.prc\n",
    "                      from crsp.msf as a\n",
    "                      left join crsp.msenames as b\n",
    "                      on a.permno=b.permno\n",
    "                      and b.namedt<=a.date\n",
    "                      and a.date<=b.nameendt\n",
    "                      where a.date between '07/01/1965' and '12/31/2019'\n",
    "                      and b.exchcd between 1 and 3\n",
    "                      \"\"\", date_cols=['date']) \n",
    "\n",
    "# change variable format to int\n",
    "crsp_m[['permco','permno','shrcd','exchcd', 'siccd']]=crsp_m[['permco','permno','shrcd','exchcd', 'siccd']].astype(int)\n",
    "\n",
    "# Line up date to be end of month\n",
    "crsp_m['jdate']=crsp_m['date']+MonthEnd(0)\n",
    "\n",
    "# add delisting return\n",
    "dlret = conn.raw_sql(\"\"\"\n",
    "                     select permno, dlret, dlstdt \n",
    "                     from crsp.msedelist\n",
    "                     \"\"\", date_cols=['dlstdt'])\n",
    "\n",
    "dlret.permno=dlret.permno.astype(int)\n",
    "#dlret['dlstdt']=pd.to_datetime(dlret['dlstdt'])\n",
    "dlret['jdate']=dlret['dlstdt']+MonthEnd(0)\n",
    "\n",
    "crsp = pd.merge(crsp_m, dlret, how='left',on=['permno','jdate'])\n",
    "crsp['dlret']=crsp['dlret'].fillna(0)\n",
    "crsp['ret']=crsp['ret'].fillna(0)\n",
    "\n",
    "# retadj factors in the delisting returns\n",
    "crsp['retadj']=(1+crsp['ret'])*(1+crsp['dlret'])-1\n",
    "\n",
    "# calculate market equity\n",
    "crsp['me']=crsp['prc'].abs()*crsp['shrout'] \n",
    "crsp=crsp.drop(['dlret','dlstdt','prc','shrout'], axis=1)\n",
    "crsp=crsp.sort_values(by=['jdate','permco','me'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49fc2d9a-1a3f-4f80-9a6d-027ad4749180",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Aggregate Market Cap ###\n",
    "# sum of me across different permno belonging to same permco a given date\n",
    "crsp_summe = crsp.groupby(['jdate','permco'])['me'].sum().reset_index()\n",
    "\n",
    "# largest mktcap within a permco/date\n",
    "crsp_maxme = crsp.groupby(['jdate','permco'])['me'].max().reset_index()\n",
    "\n",
    "# join by jdate/maxme to find the permno\n",
    "crsp1=pd.merge(crsp, crsp_maxme, how='inner', on=['jdate','permco','me'])\n",
    "\n",
    "# drop me column and replace with the sum me\n",
    "crsp1=crsp1.drop(['me'], axis=1)\n",
    "\n",
    "# join with sum of me to get the correct market cap info\n",
    "crsp2=pd.merge(crsp1, crsp_summe, how='inner', on=['jdate','permco'])\n",
    "\n",
    "# sort by permno and date and also drop duplicates\n",
    "crsp2=crsp2.sort_values(by=['permno','jdate']).drop_duplicates()\n",
    "\n",
    "# keep December market cap\n",
    "crsp2['year']=crsp2['jdate'].dt.year\n",
    "crsp2['month']=crsp2['jdate'].dt.month\n",
    "decme=crsp2[crsp2['month']==12]\n",
    "decme=decme[['permno','date','jdate','me','year']].rename(columns={'me':'dec_me'})\n",
    "\n",
    "### July to June dates\n",
    "crsp2['ffdate']=crsp2['jdate']+MonthEnd(-6)\n",
    "crsp2['ffyear']=crsp2['ffdate'].dt.year\n",
    "crsp2['ffmonth']=crsp2['ffdate'].dt.month\n",
    "crsp2['1+retx']=1+crsp2['retx']\n",
    "crsp2=crsp2.sort_values(by=['permno','date'])\n",
    "\n",
    "# cumret by stock\n",
    "crsp2['cumretx']=crsp2.groupby(['permno','ffyear'])['1+retx'].cumprod()\n",
    "\n",
    "# lag cumret\n",
    "crsp2['lcumretx']=crsp2.groupby(['permno'])['cumretx'].shift(1)\n",
    "\n",
    "# lag market cap\n",
    "crsp2['lme']=crsp2.groupby(['permno'])['me'].shift(1)\n",
    "\n",
    "# if first permno then use me/(1+retx) to replace the missing value\n",
    "crsp2['count']=crsp2.groupby(['permno']).cumcount()\n",
    "crsp2['lme']=np.where(crsp2['count']==0, crsp2['me']/crsp2['1+retx'], crsp2['lme'])\n",
    "\n",
    "# baseline me\n",
    "mebase=crsp2[crsp2['ffmonth']==1][['permno','ffyear', 'lme']].rename(columns={'lme':'mebase'})\n",
    "\n",
    "# merge result back together\n",
    "crsp3=pd.merge(crsp2, mebase, how='left', on=['permno','ffyear'])\n",
    "crsp3['wt']=np.where(crsp3['ffmonth']==1, crsp3['lme'], crsp3['mebase']*crsp3['lcumretx'])\n",
    "\n",
    "decme['year']=decme['year']+1\n",
    "decme=decme[['permno','year','dec_me']]\n",
    "\n",
    "# Info as of June\n",
    "crsp3_jun = crsp3[crsp3['month']==6]\n",
    "\n",
    "crsp_jun = pd.merge(crsp3_jun, decme, how='inner', on=['permno','year'])\n",
    "crsp_jun=crsp_jun[['permno','date', 'jdate', 'shrcd','exchcd','siccd','retadj','me','wt','cumretx','mebase','lme','dec_me']]\n",
    "crsp_jun=crsp_jun.sort_values(by=['permno','jdate']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3080ff4-a177-491d-b091-a390ddaaac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "# CCM Block           #\n",
    "#######################\n",
    "ccm=conn.raw_sql(\"\"\"\n",
    "                  select gvkey, lpermno as permno, linktype, linkprim, \n",
    "                  linkdt, linkenddt\n",
    "                  from crsp.ccmxpf_linktable\n",
    "                  where substr(linktype,1,1)='L'\n",
    "                  and (linkprim ='C' or linkprim='P')\n",
    "                  \"\"\", date_cols=['linkdt', 'linkenddt'])\n",
    "\n",
    "# if linkenddt is missing then set to today date\n",
    "ccm['linkenddt']=ccm['linkenddt'].fillna(pd.to_datetime('today'))\n",
    "\n",
    "ccm1=pd.merge(comp[['gvkey','datadate','year','be', 'count','capx', 'xrd', 'dltis', 'csho', 'cdvc', 'sale', 'ppent', 'invt', 'sppe', 'at', 'emp', 'ebit', 'sic','cik']],ccm,how='left',on=['gvkey'])\n",
    "# this construction of jdate is just to facilitate the merge of me of june from next year to compustat data\n",
    "ccm1['yearend']=ccm1['datadate']+YearEnd(0)\n",
    "ccm1['jdate']=ccm1['yearend']+MonthEnd(6)\n",
    "\n",
    "# set link date bounds\n",
    "ccm2=ccm1[(ccm1['jdate']>=ccm1['linkdt'])&(ccm1['jdate']<=ccm1['linkenddt'])]\n",
    "ccm2=ccm2[['gvkey','permno','year','datadate','be', 'count','capx','jdate', 'xrd', 'dltis', 'csho', 'cdvc', 'sale', 'ppent', 'invt', 'sppe','at', 'emp', 'ebit', 'sic','cik']]\n",
    "\n",
    "# link comp and crsp\n",
    "ccm_jun=pd.merge(crsp_jun, ccm2, how='inner', on=['permno', 'jdate'])\n",
    "ccm_jun['beme']=ccm_jun['be']*1000/ccm_jun['dec_me']\n",
    "\n",
    "# First use historical Compustat SIC Code\n",
    "# Then if missing use historical CRSP SIC Code\n",
    "ccm_jun['sic']=np.where(ccm_jun['sic']>0, ccm_jun['sic'], ccm_jun['siccd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e5283b7-2aa9-41d7-8fda-3c9c5ed615eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take from constructed annaul table\n",
    "belo_rep = ccm_jun[['permno', 'invt', 'capx', 'sppe', 'ppent', 'sale', 'at', 'be', 'me', 'jdate', 'beme', 'count']]\n",
    "belo_rep = belo_rep.sort_values(by=['permno','jdate'])\n",
    "# adjust for the unit\n",
    "belo_rep['me'] =  belo_rep['me']/1000\n",
    "# In case of zero inventory, drop them to avoid inf growth rate, hold on for this for further discussion\n",
    "# belo_rep = belo_rep[belo_rep['invt']!=0]\n",
    "belo_rep = belo_rep.reset_index(drop=True)\n",
    "\n",
    "# import cpi from downloaded csv from FRED: https://fred.stlouisfed.org/series/FPCPITOTLZGUSA\n",
    "cpi = pd.read_csv('../Data/cpi.csv', parse_dates=['DATE'])  \n",
    "# Note that this 6+12 adjustment is in line with the jdate treatment\n",
    "# basically for an annual report of 2019, its jdate will be 2020.06, we hope to deflate it with cpi from 2019 \n",
    "cpi.DATE = cpi.DATE+MonthEnd(6+12)\n",
    "cpi = cpi.rename(columns={\"DATE\":'jdate','FPCPITOTLZGUSA':'cpi'})\n",
    "cpi.cpi = cpi.cpi/100+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4f2c2a0-de9c-4d96-b38f-125e1928a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge cpi with belo_rep\n",
    "belo_repm = pd.merge(belo_rep, cpi, on=['jdate'],  how='left')\n",
    "\n",
    "# remove the first observation of a firm entering the sample\n",
    "belo_repm = belo_repm[belo_repm['count']>0]\n",
    "\n",
    "# fill nan with zeros for mostly sppe \n",
    "var_list = ['capx','sppe', 'invt']\n",
    "belo_repm[var_list] = belo_repm[var_list].fillna(0)\n",
    "# 44000+ invt==0 sample\n",
    "# belo_repm[belo_repm.invt==0].groupby(['jdate']).permno.nunique()\n",
    "\n",
    "# remove invt==0 obs\n",
    "belo_repm = belo_repm[belo_repm.invt!=0]\n",
    "\n",
    "# dropna\n",
    "# alternatively, I can interpolate by group:\n",
    "# df.groupby('filename').apply(lambda group: group.interpolate(method='index'))\n",
    "belo_repm = belo_repm.dropna()\n",
    "# belo_repm = belo_repm.fillna(0)\n",
    "# this is to make sure non-subsequent year records are not mistakenly connected \n",
    "belo_repm = belo_repm[belo_repm.groupby(['permno'])['count'].diff().fillna(1)==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5abe11f3-786e-47f3-9459-561ce597e0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/sas/jupyterhub/prod/venvs/20210519/lib/python3.9/site-packages/pandas/core/arraylike.py:358: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# create coresponding variables:\n",
    "# hn: inventory investment rate in real term\n",
    "# ik: physical capital investment rate\n",
    "# sg: real sales growth \n",
    "# ns: inventory-to-sales ratio\n",
    "\n",
    "# it's important to do groupby for the subtracted term\n",
    "\n",
    "\n",
    "belo_repm['hn'] = (belo_repm.invt/belo_repm.cpi-belo_repm.groupby(['permno']).invt.shift(1))/belo_repm.groupby(['permno']).invt.shift(1)\n",
    "\n",
    "belo_repm['ik'] = (belo_repm['capx'] - belo_repm['sppe'])/belo_repm.groupby(['permno']).ppent.shift(1)\n",
    "\n",
    "belo_repm['sg'] = (belo_repm.sale/belo_repm.cpi-belo_repm.groupby(['permno']).sale.shift(1))/belo_repm.groupby(['permno']).sale.shift(1)\n",
    "\n",
    "belo_repm['ns'] = belo_repm.invt/belo_repm.sale\n",
    "\n",
    "belo_repm['k/me'] = belo_repm.ppent/belo_repm.me\n",
    "\n",
    "belo_repm['lev'] = (belo_repm['at']-belo_repm.be)/(belo_repm['at']-belo_repm.be+belo_repm.me)\n",
    "\n",
    "belo_repm['bm'] = belo_repm.be/belo_repm.me\n",
    "\n",
    "belo_repm['size'] = np.log(belo_repm.me) \n",
    "\n",
    "belo_repm = belo_repm.dropna()\n",
    "# belo_repm = belo_repm.fillna(0)\n",
    "\n",
    "belo_repm.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "# some code to first calculate mean of each permno and then take average\n",
    "# wsrz_var = ['ik', 'hn', 'sg', 'ns','permno']\n",
    "# wsrz = belo_repm[wsrz_var].clip(lower=belo_repm[wsrz_var].quantile(0.01), upper=belo_repm[wsrz_var].quantile(0.99), axis=1)\n",
    "# des = wsrz.groupby('permno')[['ik', 'hn', 'sg', 'ns']].std()\n",
    "# pd.DataFrame(des.mean()).unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc893729-9282-4057-9217-0c4a148a1f9b",
   "metadata": {},
   "source": [
    "#### Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af51a90d-660c-4b83-bbd7-fb333b15b60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/sas/jupyterhub/prod/venvs/20210519/lib/python3.9/site-packages/numpy/lib/function_base.py:2634: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wsrz_var = ['ik', 'hn', 'sg', 'ns']\n",
    "# I have to make the winsorizing more strict to get comparable results with Belo\n",
    "wsrz = belo_repm[wsrz_var].clip(lower=belo_repm[wsrz_var].quantile(0.05), upper=belo_repm[wsrz_var].quantile(0.95), axis=1)\n",
    "\n",
    "# specify percentile to include in the summary stats\n",
    "summary_table = wsrz.describe(percentiles =  [.1, .9]).transpose()\n",
    "# summary_table.columns.tolist()\n",
    "summary_table['count'] = summary_table['count'].astype(int)\n",
    "summary_table = summary_table[['mean', 'std', '10%', '90%']]\n",
    "# make a df to record all means from ac1 calculation\n",
    "test = pd.DataFrame()\n",
    "for var in wsrz_var:\n",
    "    test[var]=belo_repm.groupby('permno')[var].apply(pd.Series.autocorr, lag=1).reset_index(name=var)[var]\n",
    "# attach the result to summary table\n",
    "summary_table['ac1'] = test.mean()\n",
    "\n",
    "# rearrange the sequence of column names \n",
    "summary_table = summary_table[['mean', 'std','ac1', '10%', '90%']]\n",
    "# calculate ac1 for each permno\n",
    "corrmatrix = belo_repm.groupby('permno')[wsrz_var].corr()\n",
    "# calculate the average of these correlation coef\n",
    "corr_matrix = pd.DataFrame(corrmatrix.unstack().mean()).unstack().droplevel(0, axis=1) \n",
    "# concat horizontally \n",
    "result = pd.concat([summary_table, corr_matrix], axis=1)\n",
    "# drop ik to be inline with belo's table\n",
    "result = result.drop(['ik'], axis=1).round(2)\n",
    "\n",
    "# prepare for the multi index\n",
    "level1_col = result.columns.tolist()\n",
    "level0_col = ['empty']*3 + ['Percentile'] *2 + ['Correlations']*3\n",
    "arrays = [level0_col , level1_col]\n",
    "tuples = list(zip(*arrays))\n",
    "multi_col = pd.MultiIndex.from_tuples(tuples)\n",
    "result.columns=multi_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f150534c-f864-45de-ac36-b1fea6fd94c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the combination to generate a latex table for the summary statistics\n",
    "importlib.reload(output)\n",
    "from output import Tolatex\n",
    "Tolatex(result, 'summary_stats.tex')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21d9032-5bfb-40a3-bc6b-a69408d98375",
   "metadata": {},
   "source": [
    "#### One way sort by inventory growth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17b1999c-462d-4c23-99ba-2f2ce5fcb2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ow_sort = belo_repm.copy().reset_index(drop=True)\n",
    "ow_sort['hnport'] = ow_sort.groupby('jdate')['hn'].apply(pd.qcut, 10, labels = False)+1\n",
    "# create positivebmeme and nonmissport variable\n",
    "ow_sort['posbm']=np.where((ow_sort['beme']>0)&(ow_sort['me']>0)&(ow_sort['count']>=1), 1, 0)\n",
    "ow_sort['nonmissport']=np.where((ow_sort['hnport']!=''), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "548c9e12-4e47-4d5c-9366-37c68aa8c615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-96a19d2212fe>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  june['ffyear']=june['jdate'].dt.year\n"
     ]
    }
   ],
   "source": [
    "# store portfolio assignment as of June\n",
    "june_list = ['hn', 'ik', 'size', 'beme', 'k/me', 'lev', 'permno','jdate', 'hnport','posbm','nonmissport']\n",
    "june=ow_sort[june_list]\n",
    "june['ffyear']=june['jdate'].dt.year\n",
    "\n",
    "# merge back with monthly records\n",
    "crsp3 = crsp3[['date','permno','shrcd','exchcd','retadj','me','wt','cumretx','ffyear','jdate']]\n",
    "ccm3=pd.merge(crsp3, \n",
    "        june[['hn', 'ik', 'size', 'beme', 'k/me', 'lev', 'permno','ffyear', 'hnport','posbm','nonmissport']], how='left', on=['permno','ffyear'])\n",
    "\n",
    "# keeping only records that meet the criteria\n",
    "ccm4=ccm3[(ccm3['wt']>0)& (ccm3['posbm']==1) & (ccm3['nonmissport']==1) & \n",
    "          ((ccm3['shrcd']==10) | (ccm3['shrcd']==11))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b55738c-0bbd-4836-8b57-fcb58941849a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "# calculate one way sorting portfolio returns #\n",
    "############################\n",
    "\n",
    "\n",
    "importlib.reload(computation)\n",
    "from computation import wavg\n",
    "from computation import ts_reg\n",
    "from computation import make_owt\n",
    "\n",
    "# to match belo's sample period\n",
    "# vwret = vwret[vwret.jdate<'2009-12-31']\n",
    "\n",
    "# equal-weighted return\n",
    "ewret=ccm4.groupby(['jdate','hnport'])[['retadj']].mean().reset_index()\n",
    "ewret[['hnport']] = ewret[['hnport']].astype(int)\n",
    "\n",
    "# value-weighted return\n",
    "vwret=ccm4.groupby(['jdate','hnport']).apply(wavg, 'retadj','wt').to_frame().reset_index().rename(columns={0: 'vwret'})\n",
    "vwret[['hnport']] = vwret[['hnport']].astype(int)\n",
    "\n",
    "###################\n",
    "# time series regression with FF #\n",
    "###################\n",
    "# smb\tdouble\tSmall Minus Big (SMB) (smb)\n",
    "# hml\tdouble\tHigh Minus Low (HML) (hml)\n",
    "# mktrf\tdouble\tExcess Return on the Market (MKTRF) (mktrf)\n",
    "# rf\tdouble\tRisk-Free Interest Rate (One Month Treasury Bill Rate) (RF) (rf)\n",
    "# umd\tdouble\tMomentum (UMD) (umd)\n",
    "\n",
    "_ff = conn.get_table(library='ff', table='factors_monthly')\n",
    "_ff=_ff[['date','smb','hml', 'mktrf', 'rf']]\n",
    "_ff['jdate']=_ff['date']+MonthEnd(0)\n",
    "\n",
    "## Create panel a part 1 of table 2\n",
    "pewret = ewret.pivot(index='jdate', columns='hnport', values='retadj')\n",
    "pewret.columns.name = None\n",
    "pewret = pewret.reset_index()\n",
    "panel_a1 = make_owt(pewret, _ff)\n",
    "\n",
    "\n",
    "## Create panel a part 2 of table 2\n",
    "pvwret = vwret.pivot(index='jdate', columns='hnport', values='vwret')\n",
    "panel_a2 = make_owt(pvwret, _ff)\n",
    "\n",
    "## Create panel b of table 2\n",
    "pb_var = ['hn', 'ik', 'size', 'beme', 'k/me', 'lev']\n",
    "panel_b = ccm4.groupby(['jdate','hnport'])[pb_var].median().reset_index()\n",
    "panel_b = panel_b.groupby('hnport')[pb_var].mean().T.round(2)\n",
    "panel_b['L-H'] = panel_b[1] - panel_b[10] \n",
    "panel_b['MAE'] = ''\n",
    "panel_b.columns = panel_a1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0d860d-e076-4120-a55d-43434031beb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(output)\n",
    "from output import Tolatex\n",
    "Tolatex(panel_a1, 'panel_a1.tex')\n",
    "Tolatex(panel_a2, 'panel_a2.tex')\n",
    "Tolatex(panel_b, 'panel_b.tex')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
